{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory\n",
    "Memory allows you to bring previous messages, instructions and responses into the context of a new prompt. This is particularly useful for chatbots and conversation chains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by initiating the LLM object with a built-in OpenAI chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=\"KEY-ABC-DEF\",\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some orchestration frameworks (like LangChain) have callback handlers to monitor and log LLM tasks. Here we can monitor how many tokens have been submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "def count_tokens(chain, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = chain.run(query)\n",
    "        print(f\"Spent a total of {cb.total_tokens} tokens\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define the conversation chain with a memory argument. In this case we are using Summary Memory, which is useful for keeping token counts down on longer conversations. Summary memory makes use of an LLM to create the summary, so that should also be considered in the final token count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
    "\n",
    "conversation_sum = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationSummaryMemory(llm=llm)\n",
    ")\n",
    "\n",
    "print(conversation_sum.memory.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following prompts, watch how the conversation history element changes in the LLM response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me something about weather in 2018.\"\n",
    "conversation_sum(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Were there any particularly long lasting storms in 2018?\"\n",
    "conversation_sum(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What were we just talking about?\"\n",
    "conversation_sum(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conversation_sum.memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For applications with recurring users, or long lasting conversations, a database can be used to persist conversation histories. Here we will store each history entry in a seperate row, for simple access with SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intersystems_iris.dbapi._DBAPI as iris\n",
    "\n",
    "conn = iris.connect(hostname='localhost', \n",
    "                    port=51972, \n",
    "                    namespace='USER',\n",
    "                    username='SuperUser', \n",
    "                    password='SYS')\n",
    "\n",
    "# Create a table to store message prompts and responses.\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "        CREATE TABLE RAG_Application.ConversationHistory (\n",
    "            Username VARCHAR(100),\n",
    "            ConversationTitle VARCHAR(250),\n",
    "            HumanMessage VARCHAR(10000),\n",
    "            AIMessage VARCHAR(10000)\n",
    "        )\n",
    "    \"\"\")\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can store the conversation messages in a relational table, just using SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = input(\"Enter your username\")\n",
    "chat_history = conversation_sum.memory.chat_memory.messages\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for i in range(0,len(chat_history),2):\n",
    "    conversation_title = \"This title\"\n",
    "    human_message = chat_history[i].content\n",
    "    ai_message = chat_history[i+1].content\n",
    "    cursor.execute(f\"\"\"INSERT INTO RAG_Application.ConversationHistory (Username, ConversationTitle, HumanMessage, AIMessage)\n",
    "                   VALUES ('{username}', '{conversation_title}', '{human_message}', '{ai_message}')\"\"\")\n",
    "\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the persisted conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(f\"\"\"SELECT HumanMessage, AIMessage FROM RAG_Application.ConversationHistory \n",
    "               WHERE Username = '{username}' AND ConversationTitle = '{conversation_title}'\"\"\")\n",
    "\n",
    "for row in cursor.fetchall():\n",
    "    print(row)\n",
    "\n",
    "cursor.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
