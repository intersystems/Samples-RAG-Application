{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n",
    "\n",
    "Agents abstract sequences of actions, allowing a Language Model to effectively choose which action would be most appropriate for a request. Typically an Agent is provided with an LLM, search tools such as a vector database, a search engine or a file system and prompting techniques to use. With some RAG frameworks, it is easy to also return the intermediary steps that an Agent has taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the LLM to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SRC\\Non-PoC\\rag-learning-services\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "import keys\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=\"KEY-ABC-DEF\",\n",
    "    temperature=0,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can initialize the agent with our search mechanism, our LLM and the prompting technique. Then, run a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "agent = initialize_agent([search], llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "result = agent.run(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a table in the database to store the data for the RAG application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up database\n",
    "import intersystems_iris.dbapi._DBAPI as iris\n",
    "\n",
    "conn = iris.connect(hostname='localhost', \n",
    "                    port=51972, \n",
    "                    namespace='USER',\n",
    "                    username='SuperUser', \n",
    "                    password='SYS')\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"CREATE TABLE RAG_Application.StockObservation (\n",
    "            Obs_id INTEGER,\n",
    "            Stock_ticker VARCHAR(4),\n",
    "            Price DOUBLE,\n",
    "            Date_t DATE)\"\"\")\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist the observations in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = [\n",
    "    [1, 'ABC', 200, '2023-01-01'],\n",
    "    [2, 'ABC', 208, '2023-01-02'],\n",
    "    [3, 'ABC', 232, '2023-01-03'],\n",
    "    [4, 'ABC', 225, '2023-01-04'],\n",
    "    [5, 'ABC', 226, '2023-01-05'],\n",
    "    [6, 'XYZ', 810, '2023-01-01'],\n",
    "    [7, 'XYZ', 803, '2023-01-02'],\n",
    "    [8, 'XYZ', 798, '2023-01-03'],\n",
    "    [9, 'XYZ', 795, '2023-01-04'],\n",
    "    [10, 'XYZ', 791, '2023-01-05']\n",
    "]\n",
    "\n",
    "cursor = conn.cursor()\n",
    "query = \"INSERT INTO RAG_Application.StockObservation (Obs_id, Stock_ticker, Price, Date_t) VALUES (?,?,?,?)\"\n",
    "\n",
    "cursor.executemany(query, observations)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use SQLAlchemy to bridge LangChain and our SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "iris_url = \"iris://SuperUser:SYS@localhost:51972/USER\"\n",
    "engine = create_engine(iris_url, echo=True)\n",
    "\n",
    "db = SQLDatabase.from_uri(iris_url, schema=\"RAG_Application\", view_support=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StockObservation']\n"
     ]
    }
   ],
   "source": [
    "# We can see which tables will be accessed by the SQL agent after defining the URI\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a Zero-Shot agent on our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_sql_agent, Tool, AgentType\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm = llm,\n",
    "    toolkit = SQLDatabaseToolkit(db=db, llm=llm),\n",
    "    verbose = True,\n",
    "    agent_type = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    max_iterations = 15, # You may need several iterations for the LLM to correctly query any paticular database. Otherwise, try few-shot!\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the tokens using LLM callbacks again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "def count_tokens(agent, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = agent(query)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit a query to the Agent executor. It should use our SQL Database tool, and correctly query the relevant tables (might take a few attempts). If the query is malformed, the LLM will make use of any DB errors and modify the query for the next attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mWe need to calculate the ratios for stock observations and stock prices for 'ABC' and 'XYZ' on January 3rd and January 4th.\n",
      "Action: sql_db_list_tables\n",
      "Action Input: \u001b[0m\u001b[38;5;200m\u001b[1;3mStockObservation\u001b[0m\u001b[32;1m\u001b[1;3mWe need to check the fields in the StockObservation table.\n",
      "Action: sql_db_schema\n",
      "Action Input: StockObservation\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE \"RAG_Application\".\"StockObservation\" (\n",
      "\t\"Obs_id\" INTEGER, \n",
      "\t\"Stock_ticker\" VARCHAR(4), \n",
      "\t\"Price\" DOUBLE, \n",
      "\t\"Date_t\" DATE\n",
      ") WITH %CLASSPARAMETER ALLOWIDENTITYINSERT = 1\n",
      "\n",
      "/*\n",
      "3 rows from StockObservation table:\n",
      "Obs_id\tStock_ticker\tPrice\tDate_t\n",
      "1\tABC\t200.0\t2023-01-01\n",
      "2\tABC\t208.0\t2023-01-02\n",
      "3\tABC\t232.0\t2023-01-03\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mWe need to write a query to calculate the ratios for stock observations and stock prices for 'ABC' and 'XYZ' on January 3rd and January 4th.\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT Price FROM StockObservation WHERE Stock_ticker = 'ABC' AND Date_t = '2023-01-03'\u001b[0m\u001b[36;1m\u001b[1;3mError: (intersystems_iris.dbapi._DBAPI.DatabaseError) [SQLCODE: <-30>:<Table or view not found>]\n",
      "[Location: <Prepare>]\n",
      "[%msg: < Table 'SQLUSER.STOCKOBSERVATION' not found>]\n",
      "[SQL: SELECT Price FROM StockObservation WHERE Stock_ticker = 'ABC' AND Date_t = '2023-01-03']\n",
      "(Background on this error at: https://sqlalche.me/e/20/4xp6)\u001b[0m\u001b[32;1m\u001b[1;3mWe need to use the correct table name in the query.\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT Price FROM \"RAG_Application\".\"StockObservation\" WHERE Stock_ticker = 'ABC' AND Date_t = '2023-01-03'\u001b[0m\u001b[36;1m\u001b[1;3m[(232.0,), (232.0,)]\u001b[0m\u001b[32;1m\u001b[1;3mWe need to calculate the ratios for stock observations and stock prices for 'ABC' and 'XYZ' on January 3rd and January 4th.\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT Price FROM \"RAG_Application\".\"StockObservation\" WHERE Stock_ticker = 'XYZ' AND Date_t = '2023-01-03'\u001b[0m\u001b[36;1m\u001b[1;3m[(798.0,), (798.0,)]\u001b[0m\u001b[32;1m\u001b[1;3mWe have the stock prices for 'ABC' and 'XYZ' on January 3rd. Now we need to get the stock prices for the same stocks on January 4th.\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT Price FROM \"RAG_Application\".\"StockObservation\" WHERE Stock_ticker = 'ABC' AND Date_t = '2023-01-04'\u001b[0m\u001b[36;1m\u001b[1;3m[(225.0,), (225.0,)]\u001b[0m\u001b[32;1m\u001b[1;3mWe have the stock prices for 'ABC' on January 3rd and 4th. Now we need to get the stock price for 'XYZ' on January 4th.\n",
      "Action: sql_db_query\n",
      "Action Input: SELECT Price FROM \"RAG_Application\".\"StockObservation\" WHERE Stock_ticker = 'XYZ' AND Date_t = '2023-01-04'\u001b[0m\u001b[36;1m\u001b[1;3m[(795.0,), (795.0,)]\u001b[0m\u001b[32;1m\u001b[1;3mI now have all the necessary stock prices to calculate the ratios.\n",
      "Final Answer: The multiplication of the ratio between stock observations for 'ABC' and 'XYZ' in January 3rd is (232/798) * (225/795).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    agent_executor,\n",
    "    \"What is the multiplication of the ratio between stock \" +\n",
    "    \"observations for 'ABC' and 'XYZ' in January 3rd and the ratio \" +\n",
    "    \"between the same stock prices in January the 4th?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try different agents as well, like a Conversational React with buffer memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    ['llm-math'], \n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "conversational_agent = initialize_agent(\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Calculator\n",
      "Action Input: investment amount = $10,000, annual interest rate = 8%, number of years = 5, compound interest\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 14693.280768000006\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: The result of an investment of $10,000 growing at 8% annually for 5 years with compound interest would be approximately $14,693.28.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversational_agent,\n",
    "    \"What's the result of an investment of $10,000 growing at 8% annually for 5 years with compound interest?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
